\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Regression}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Linear Regression}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Code examples}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Four examples of the function found by linear regression based on the given data points.}}{5}}
\newlabel{fig:linearregression}{{2.1}{5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Classification}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}K Nearest Neighbors}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Code examples}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Support Vector Machines}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces  Shows the support vectors for this SVM classification problem.}}{7}}
\newlabel{fig:svm-support-vectors}{{3.1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces  Shows the decision boundary for this SVM classification problem.}}{7}}
\newlabel{fig:svm-decision-boundary}{{3.2}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Code examples}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Support Vector Machine Regression}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces  Shows three seperation planes, H1 is not a good seperating plane, H2 and H3 are acceptable.}}{8}}
\newlabel{fig:svm}{{3.3}{8}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Clustering}{9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:clustering}{{4}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}General Terms}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:general_terms}{{5}{10}}
\@writefile{toc}{\contentsline {paragraph}{Confidence Score}{10}}
\@writefile{toc}{\contentsline {paragraph}{Cross Validation}{10}}
\@writefile{toc}{\contentsline {paragraph}{Decision Boundary}{10}}
\@writefile{toc}{\contentsline {paragraph}{Eucledian Distance}{10}}
\@writefile{toc}{\contentsline {paragraph}{Eucledian Norm}{10}}
\@writefile{toc}{\contentsline {paragraph}{Features}{10}}
\@writefile{toc}{\contentsline {paragraph}{Hyperplane}{10}}
\@writefile{toc}{\contentsline {paragraph}{Kernels}{10}}
\@writefile{toc}{\contentsline {paragraph}{Labels}{10}}
\@writefile{toc}{\contentsline {paragraph}{Linear Algebra}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  An example of simplifying the data by increasing it's dimension.}}{10}}
\newlabel{fig:kernelmethods}{{5.1}{10}}
\@writefile{toc}{\contentsline {paragraph}{(Maximum) Margin Classifier}{11}}
\@writefile{toc}{\contentsline {paragraph}{Preprocessing}{11}}
\@writefile{toc}{\contentsline {paragraph}{Machine Learning Classifier}{11}}
\@writefile{toc}{\contentsline {paragraph}{Machine Learning Model}{11}}
\@writefile{toc}{\contentsline {paragraph}{Supervised Learning}{11}}
\@writefile{toc}{\contentsline {paragraph}{R squared method}{11}}
\@writefile{toc}{\contentsline {paragraph}{Support Vector}{11}}
\@writefile{toc}{\contentsline {paragraph}{Threading}{11}}
\@writefile{toc}{\contentsline {paragraph}{Types of Data}{11}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{12}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Regression}{13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:regression}{{A}{13}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/LinearRegression/Regression.py}{13}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Manual Regression}{16}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:manualregression}{{B}{16}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/LinearRegression/ManualRegression.py}{16}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}K Nearest Neighbors}{18}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:knn}{{C}{18}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KNearestNeighbors/KNearestNeighbors.py}{18}}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Manual K Nearest Neighbors}{19}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:mknn}{{D}{19}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KNearestNeighbors/ManualKNearestNeighbors.py}{19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {E}Support Vector Machine}{22}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:svm}{{E}{22}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/SVM/SVM.py}{22}}
\@writefile{toc}{\contentsline {chapter}{\numberline {F}Manual Support Vector Machine}{23}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:msvm}{{F}{23}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/SVM/ManualSVM.py}{23}}
