\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Acknowledgements}{4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Regression}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Linear Regression}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Code examples}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Four examples of the function found by linear regression based on the given data points.}}{6}}
\newlabel{fig:linearregression}{{2.1}{6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Classification}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}K Nearest Neighbors}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Code examples}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Support Vector Machines}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces  Shows the support vectors for this SVM classification problem.}}{8}}
\newlabel{fig:svm-support-vectors}{{3.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces  Shows the decision boundary for this SVM classification problem.}}{8}}
\newlabel{fig:svm-decision-boundary}{{3.2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Kernels}{8}}
\newlabel{sub:kernel}{{3.2.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces  Shows the results of van OVR classification.}}{9}}
\newlabel{fig:ovr}{{3.3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Soft Margin SVMs}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}OVR and OVO}{9}}
\newlabel{sub:ovr_ovo}{{3.2.3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Code examples}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Clustering}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:clustering}{{4}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}K-Means}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Code examples}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Mean Shift}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Code examples}{11}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Neural Network}{12}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Feed Forward Neural Networks}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}LTSM Neural Networks}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  Shows the detailed working for one node in an artificial neural network.}}{13}}
\newlabel{fig:nnd}{{5.1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces  Shows the general overview of an artificial neural network.}}{13}}
\newlabel{fig:nno}{{5.2}{13}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}General Terms}{14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:general_terms}{{6}{14}}
\@writefile{toc}{\contentsline {paragraph}{Backpropagation}{14}}
\@writefile{toc}{\contentsline {paragraph}{Centroids}{14}}
\@writefile{toc}{\contentsline {paragraph}{Confidence Score}{14}}
\@writefile{toc}{\contentsline {paragraph}{Convex}{14}}
\@writefile{toc}{\contentsline {paragraph}{Cross Validation}{14}}
\@writefile{toc}{\contentsline {paragraph}{Deterministic Enviroment}{14}}
\@writefile{toc}{\contentsline {paragraph}{Decision Boundary}{14}}
\@writefile{toc}{\contentsline {paragraph}{Dot Product}{14}}
\@writefile{toc}{\contentsline {paragraph}{Epoch}{14}}
\@writefile{toc}{\contentsline {paragraph}{Eucledian Distance}{14}}
\@writefile{toc}{\contentsline {paragraph}{Eucledian Norm}{14}}
\@writefile{toc}{\contentsline {paragraph}{Features}{14}}
\@writefile{toc}{\contentsline {paragraph}{Gradient Descent}{14}}
\@writefile{toc}{\contentsline {paragraph}{Hyperplane}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces  An example of simplifying the data by increasing it's dimension.}}{15}}
\newlabel{fig:kernelmethods}{{6.1}{15}}
\@writefile{toc}{\contentsline {paragraph}{Kernels}{15}}
\@writefile{toc}{\contentsline {paragraph}{Labels}{15}}
\@writefile{toc}{\contentsline {paragraph}{Linear Algebra}{15}}
\@writefile{toc}{\contentsline {paragraph}{(Maximum) Margin Classifier}{15}}
\@writefile{toc}{\contentsline {paragraph}{Object Oriented Programming}{15}}
\@writefile{toc}{\contentsline {paragraph}{Preprocessing}{15}}
\@writefile{toc}{\contentsline {paragraph}{Machine Learning Classifier}{15}}
\@writefile{toc}{\contentsline {paragraph}{Machine Learning Model}{15}}
\@writefile{toc}{\contentsline {paragraph}{Norm}{15}}
\@writefile{toc}{\contentsline {paragraph}{One Hot}{15}}
\@writefile{toc}{\contentsline {paragraph}{Overfitting}{15}}
\@writefile{toc}{\contentsline {paragraph}{Sigmoid Function}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces  Shows underfitting, right fitting and overfitting.}}{16}}
\newlabel{fig:svm-overfitting}{{6.2}{16}}
\@writefile{toc}{\contentsline {paragraph}{Stochastic Enviroment}{16}}
\@writefile{toc}{\contentsline {paragraph}{Supervised Learning}{16}}
\@writefile{toc}{\contentsline {paragraph}{R squared method}{16}}
\@writefile{toc}{\contentsline {paragraph}{Support Vector}{16}}
\@writefile{toc}{\contentsline {paragraph}{Tensor}{16}}
\@writefile{toc}{\contentsline {paragraph}{Threading}{16}}
\@writefile{toc}{\contentsline {paragraph}{Types of Data}{16}}
\@writefile{toc}{\contentsline {paragraph}{Unsupervised Learning}{16}}
\@writefile{toc}{\contentsline {paragraph}{Vector}{16}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{17}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Regression}{18}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:regression}{{A}{18}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/LinearRegression/Regression.py}{18}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Manual Regression}{21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:manualregression}{{B}{21}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/LinearRegression/ManualRegression.py}{21}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}K Nearest Neighbors}{23}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:knn}{{C}{23}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KNearestNeighbors/KNearestNeighbors.py}{23}}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Manual K Nearest Neighbors}{24}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:mknn}{{D}{24}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KNearestNeighbors/ManualKNearestNeighbors.py}{24}}
\@writefile{toc}{\contentsline {chapter}{\numberline {E}Support Vector Machine}{27}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:svm}{{E}{27}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/SVM/SVM.py}{27}}
\@writefile{toc}{\contentsline {chapter}{\numberline {F}Manual Support Vector Machine}{28}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:msvm}{{F}{28}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/SVM/ManualSVM.py}{28}}
\@writefile{toc}{\contentsline {chapter}{\numberline {G}K-Means}{32}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:kmeans}{{G}{32}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KMeans/k\textendash means.py}{32}}
\@writefile{toc}{\contentsline {chapter}{\numberline {H}Nonnumerical K-Means}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:nonnumerical-kmeans}{{H}{33}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KMeans/nonnumerical\textendash k\textendash means.py}{33}}
\@writefile{toc}{\contentsline {chapter}{\numberline {I}Manual K-Means}{35}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:manual-kmeans}{{I}{35}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/KMeans/manual\textendash k\textendash means.py}{35}}
\@writefile{toc}{\contentsline {chapter}{\numberline {J}Mean Shift}{37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:meanshift}{{J}{37}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/MeanShift/mean\textendash shift.py}{37}}
\@writefile{toc}{\contentsline {chapter}{\numberline {K}Nonnumerical Mean Shift}{38}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:nonnumerical-meanshift}{{K}{38}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/MeanShift/nonnumerical\textendash mean\textendash shift.py}{38}}
\@writefile{toc}{\contentsline {chapter}{\numberline {L}Manual Mean Shift}{40}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{code:manual-meanshift}{{L}{40}}
\@writefile{lol}{\contentsline {lstlisting}{/home/tom/Dropbox/Workspace/Python/PracticalML/MeanShift/manual\textendash mean\textendash shift.py}{40}}
